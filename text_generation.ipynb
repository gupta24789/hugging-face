{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gupta24789/hugging-face/blob/main/text_generation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CFEtrIVIp6CW"
      },
      "source": [
        "#### Challanges in Generating Cohereent Text\n",
        "- Repetition: The model can repeat itself, generating the same text over and over again.\n",
        "- Limited Vocabulary: The model can use the same words and phrases over and over again.\n",
        "- Lack of Context: The model can generate sentences that are grammatically correct, but lack context and meaning.\n",
        "\n",
        "\n",
        "#### How to Generate Text\n",
        "\n",
        "- *Greedy Search:* The model generates the word with the highest probability as the next word.\n",
        "- *Beam Search:* The model generates the top ùëò words and keeps track of the probability of each sequence. The sequence with the highest probability is used as the next sequence.\n",
        "- *Top-K Sampling:* The model generates the top ùëò words and samples from those words using their probabilities as weights.\n",
        "- *Top-p (nucleus) Sampling:* The model generates the smallest possible set of words whose cumulative probability exceeds the probability ùëù. The model then samples from those words using their probabilities as weights."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "shB_tNCyp6Cb"
      },
      "outputs": [],
      "source": [
        "# !pip3 install -q -U bitsandbytes==0.42.0\n",
        "# !pip3 install -q -U peft==0.8.2\n",
        "# !pip3 install -q -U trl==0.7.10\n",
        "# !pip3 install -q -U accelerate==0.27.1\n",
        "# !pip3 install -q -U datasets==2.17.0\n",
        "# !pip3 install -q -U transformers==4.38.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "arouydItp6Cd"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from dotenv import load_dotenv\n",
        "load_dotenv()\n",
        "\n",
        "os.environ['CUDA_VISIBLE_DEVICES'] = \"0\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "soKkdLnZp6Ce"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
        "from pprint import pprint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a0K8Fk9vp6Cf",
        "outputId": "903a7a96-3eb4-42d4-a16d-d2fa581946af"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.cuda.device_count()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CZsI_TNbp6Cg"
      },
      "source": [
        "## Check GPU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zUDi8kiOp6Cg",
        "outputId": "c2d0bbb6-d336-4ce1-fbc4-d3fd5318d13e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'cuda'"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "device"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kU9pfQoBp6Ch"
      },
      "source": [
        "## Load Tokenizer & model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LpFv1Ulmp6Ch",
        "outputId": "1344545c-81eb-4ae0-899f-e749b13562fe",
        "colab": {
          "referenced_widgets": [
            "9c880cd229ca4627b8a71a1d0b501e60"
          ]
        }
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9c880cd229ca4627b8a71a1d0b501e60",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "model_name = \"google/gemma-2b\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name, token=os.environ['HF_TOKEN'])\n",
        "model = AutoModelForCausalLM.from_pretrained(model_name, token=os.environ['HF_TOKEN'], device_map = device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mMedOo85p6Ci"
      },
      "source": [
        "## Generate Text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yQwyqN7gp6Ci"
      },
      "outputs": [],
      "source": [
        "input_text = \"Can you please prepare the step by step roadmap to learn data science\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1EztwcOWp6Ci",
        "outputId": "73677852-83c0-48e4-93eb-03e7f6b2fb47"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'input_ids': tensor([[    2,  3611,   692,  3743, 12523,   573,  4065,   731,  4065, 96774,\n",
            "           577,  3918,  1423,  8042]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0')}\n"
          ]
        }
      ],
      "source": [
        "## encode input text\n",
        "inputs = tokenizer(input_text, return_tensors='pt').to(device)\n",
        "print(inputs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "__xzRygRp6Cj"
      },
      "source": [
        "## Beam Search"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8q-UApp8p6Cj",
        "outputId": "abcb7bab-931d-434f-d487-1d0e93fc07f7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Can you please prepare the step by step roadmap to learn data science?\n",
            "\n",
            "Answer:\n",
            "1. Understand the basics of data science. 2. Learn how to collect and analyze data. 3. Learn how to use data to make predictions. 4. Learn how to use data to make decisions.\n"
          ]
        }
      ],
      "source": [
        "max_length = 128\n",
        "output = model.generate(**inputs, max_length=max_length, num_beams=3, do_sample=False)\n",
        "print(tokenizer.decode(output[0], skip_special_tokens=True))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CuhwUZ9hp6Ck"
      },
      "source": [
        "## Beam Search with no repeat\n",
        "\n",
        "\n",
        "- no_repeat_ngram_size : This imposes the penality on number of repeats"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qiMpXocWp6Ck",
        "outputId": "7ea1b569-d881-4366-a183-0e8e755de4d0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Can you please prepare the step by step roadmap to learn data science?\n",
            "\n",
            "Answer:\n",
            "\n",
            "Step 1/10\n",
            "1. Understand the basics of statistics and data analysis: This includes learning about variables, data types, descriptive statistics, probability distributions, hypothesis testing, and inferential statistics. It is important to understand these concepts before moving on to more advanced topics. Resources: - Statistics for Business and Economics by Douglas C. Montgomery - An Introduction to Statistical Learning by Gareth James, Daniela Witten, Trevor Hastie, Robert Tibshirani - Hands-on Machine Learning with Scikit-Learn and TensorFlow by Aur√©lien G√©ron\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "max_length = 128\n",
        "output = model.generate(**inputs, max_length=max_length, num_beams=3, do_sample=False, no_repeat_ngram_size = 2)\n",
        "print(tokenizer.decode(output[0], skip_special_tokens=True))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yiLmhvBtp6Cl"
      },
      "source": [
        "## Sampling Method\n",
        "\n",
        "\n",
        "- do_sample : If True then use the sampling method\n",
        "    - top_p : nucleus sampling\n",
        "    - top_k : random sampling\n",
        "\n",
        "\n",
        "- no_repeat_ngram_size : This imposes the penality on number of repeats"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t4YT2uYkp6Cl",
        "outputId": "d58aa5e5-2861-4904-c036-4b3fbfc7cae7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Can you please prepare the step by step roadmap to learn data science? My aim is to take this knowledge and to help poor Indian youth to reduce their unemployment ratio.\n",
            "\n",
            "I have been working in that field as a data scientist since 2012 in Bangalore & Delhi. I want to take steps to increase the awareness about data science and machine learning among the people\n",
            "\n",
            "Hi. I recently started learning data science with the intention to explore ways of automating data collection to help scientists create better ML pipelines. I will be working to help others get started as well in ML and data science. I also plan to learn ways to help automate\n"
          ]
        }
      ],
      "source": [
        "## Random Sampling\n",
        "max_length = 128\n",
        "output = model.generate(**inputs, max_length=max_length, do_sample=True, top_k = 100)\n",
        "print(tokenizer.decode(output[0], skip_special_tokens=True))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xf1_XvL8p6Cl",
        "outputId": "f78c8f56-69d8-4ed0-95f2-ae67ab6ee42a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Can you please prepare the step by step roadmap to learn data science for beginners with 100% guaranteed placement in top MNCs ?\n",
            "\n",
            "I have cleared all the interviews but unable to get the job as the salary is not in my range . I am asking you for a solution\n",
            "\n",
            "I am currently doing a research project on \"Data Science\" but my professor doesn't know much about it.\n",
            "\n",
            "I have been looking for the right career for myself for a while now, and data science and data analytics is something that has been of utmost interest to me. I am currently a college student, but I have been researching the\n"
          ]
        }
      ],
      "source": [
        "## Nucleus Sampling\n",
        "max_length = 128\n",
        "output = model.generate(**inputs, max_length=max_length, do_sample=True, top_p = .8)\n",
        "print(tokenizer.decode(output[0], skip_special_tokens=True))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RlLXm7lHp6Cm",
        "outputId": "e72746f2-0969-444e-eebc-d89b00aa865d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Can you please prepare the step by step roadmap to learn data science.\n",
            "\n",
            "Can anyone please share the data analytics training material, and the way to prepare for interviews for Data Science roles. I have completed a PG in Data science and have been practicing a lot for the interviews. Can anyone help me with the right way of preparing for it. Any online resources for practice are appreciated. Thanks in advance.\n"
          ]
        }
      ],
      "source": [
        "max_length = 128\n",
        "output = model.generate(inputs['input_ids'], max_length=max_length, do_sample=True, top_p = 0.7, no_repeat_ngram_size = 2)\n",
        "print(tokenizer.decode(output[0], skip_special_tokens=True))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-k65B5Wcp6Cm"
      },
      "source": [
        "## Model with different precision"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YxHEQH0Ep6Cm",
        "outputId": "b2a13c62-b42e-4069-b348-74f7aa2208be",
        "colab": {
          "referenced_widgets": [
            "09842fc0e6d74e7698c9e5b29292d493"
          ]
        }
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "09842fc0e6d74e7698c9e5b29292d493",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "## torch.float16, torch.bfloat16\n",
        "model_name = \"google/gemma-2b\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name, token=os.environ['HF_TOKEN'])\n",
        "model = AutoModelForCausalLM.from_pretrained(model_name, token=os.environ['HF_TOKEN'], device_map = device, torch_dtype=torch.bfloat16 )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j4qAwYrTp6Cn",
        "outputId": "a3cf8773-840b-4093-c643-a9bf4838ae26"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Can you please prepare the step by step roadmap to learn data science?\n",
            "\n",
            "Answer:\n",
            "1. Identify your goals and define your data analysis tasks.\n",
            "2. Collect and prepare your dataset. 3. Analyze your collected data.\n"
          ]
        }
      ],
      "source": [
        "max_length = 512\n",
        "output = model.generate(**inputs, max_length=max_length, do_sample=True, top_p = 0.9, no_repeat_ngram_size = 2)\n",
        "print(tokenizer.decode(output[0], skip_special_tokens=True))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "thrPxQRGp6Cn"
      },
      "source": [
        "## Quantized Versions through bitsandbytes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Upad3x7dp6Cn",
        "outputId": "f612b0c2-b4d9-4a86-a19e-62c0582ed217",
        "colab": {
          "referenced_widgets": [
            "e8214b0f028b41a0ae0f2776d73b063e"
          ]
        }
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e8214b0f028b41a0ae0f2776d73b063e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "## you can load the model in qunatized version using bitsandbytes\n",
        "quantization_config = BitsAndBytesConfig(load_in_8bit=True, load_in_4bit = False)\n",
        "\n",
        "model_name = \"google/gemma-2b\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name, token=os.environ['HF_TOKEN'])\n",
        "model = AutoModelForCausalLM.from_pretrained(model_name, token=os.environ['HF_TOKEN'], device_map = device, quantization_config = quantization_config )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZuCpVsx2p6Cn",
        "outputId": "2d84f51c-830e-4a72-bbc9-9a3833ef7421"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Can you please prepare the step by step roadmap to learn data science?\n",
            "\n",
            "Answer:\n",
            "\n",
            "Step 1/6\n",
            "1. Start with a basic understanding of mathematics and statistics.\n",
            "\n",
            " Step 2. Learn about programming languages such as Python, R, or Java. Step3. Get familiar with machine learning algorithms and techniques.Step4. Practice data cleaning and data wrangling.\n",
            "Step5. Build a data model and visualize data.\n"
          ]
        }
      ],
      "source": [
        "max_length = 512\n",
        "output = model.generate(**inputs, max_length=max_length, do_sample=True, top_p = 0.6, no_repeat_ngram_size = 2)\n",
        "print(tokenizer.decode(output[0], skip_special_tokens=True))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1BkBNae7p6Co"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "lighting",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.18"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}