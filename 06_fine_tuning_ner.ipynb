{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gupta24789/hugging-face/blob/main/06_fine_tuning_ner.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pZqxQcK80dK-"
      },
      "source": [
        "## Token Classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V5uCdNaN0dLB"
      },
      "outputs": [],
      "source": [
        "!rm -rf checkpoints_logs logs mlruns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nkbFUqjA0dLC"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ['CUDA_VISIBLE_DEVICES'] = \"1\"\n",
        "os.environ['TOKENIZERS_PARALLELISM'] = \"0\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IB-I-Xao0dLD"
      },
      "outputs": [],
      "source": [
        "import itertools\n",
        "import evaluate\n",
        "import numpy as np\n",
        "from pprint import pprint\n",
        "from datasets import load_dataset\n",
        "from transformers import AutoTokenizer, TrainingArguments, Trainer, AutoModelForTokenClassification, DataCollatorForTokenClassification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HsWpwY1W0dLE"
      },
      "source": [
        "## Load Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XwCzKUU40dLE",
        "outputId": "61b77a3f-211c-47fb-d7be-bd4fd4a565ac"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['sentence', 'labels'],\n",
              "        num_rows: 33570\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['sentence', 'labels'],\n",
              "        num_rows: 7194\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['sentence', 'labels'],\n",
              "        num_rows: 7194\n",
              "    })\n",
              "})"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset = load_dataset(\"sg247/ner\")\n",
        "dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LndPnir90dLF"
      },
      "source": [
        "## Transform Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jy2o0NaA0dLG",
        "outputId": "e247d05f-051a-4d4c-ea62-d06c263fc77e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['sentence', 'labels'],\n",
              "        num_rows: 33570\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['sentence', 'labels'],\n",
              "        num_rows: 7194\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['sentence', 'labels'],\n",
              "        num_rows: 7194\n",
              "    })\n",
              "})"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset = dataset.map(lambda x: {\"sentence\":  eval(x['sentence']), \"labels\": eval(x['labels'])})\n",
        "dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EiKdyMgU0dLG",
        "outputId": "2d6900c5-8fd7-4bf6-b40f-9a6a02faa365"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'labels': ['O', 'O', 'O', 'O', 'O', 'O', 'B-geo', 'O', 'O', 'O', 'O', 'O',\n",
            "            'B-geo', 'O', 'O', 'O', 'O', 'O', 'B-gpe', 'O', 'O', 'O', 'O',\n",
            "            'O'],\n",
            " 'sentence': ['Thousands', 'of', 'demonstrators', 'have', 'marched', 'through',\n",
            "              'London', 'to', 'protest', 'the', 'war', 'in', 'Iraq', 'and',\n",
            "              'demand', 'the', 'withdrawal', 'of', 'British', 'troops', 'from',\n",
            "              'that', 'country', '.']}\n"
          ]
        }
      ],
      "source": [
        "pprint(dataset['train'][0], compact = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lV1E_rq60dLH",
        "outputId": "8e8aec42-2241-4bb8-edca-382bbd908fa9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['B-gpe', 'B-org', 'B-per', 'I-org', 'I-nat', 'I-geo', 'I-tim', 'B-eve', 'B-art', 'I-art', 'O', 'I-gpe', 'I-eve', 'B-tim', 'B-nat', 'I-per', 'B-geo']\n"
          ]
        }
      ],
      "source": [
        "unique_labels = list(set(itertools.chain.from_iterable(dataset['train'].to_pandas()['labels'].tolist())))\n",
        "print(unique_labels)\n",
        "\n",
        "id2label = dict(enumerate(unique_labels))\n",
        "label2id = {w:i for i,w in id2label.items()}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IZgJt4eH0dLH",
        "outputId": "37306fe5-a424-4842-f899-a6ebeb6d944d",
        "colab": {
          "referenced_widgets": [
            "d6bd5c245ea247829cd3b341587c0413",
            "70b6bd15c555458c8727a9da755016dc",
            "0efa32e8feac45a2b5812f5f6f6910e0"
          ]
        }
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d6bd5c245ea247829cd3b341587c0413",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/33570 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "70b6bd15c555458c8727a9da755016dc",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/7194 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0efa32e8feac45a2b5812f5f6f6910e0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/7194 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "dataset = dataset.map(lambda x: {\"labels\": [label2id[label] for label in x['labels']]})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C2KQSzHJ0dLI",
        "outputId": "2188ec7f-f294-4fa0-f4a7-d006fda335b0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'labels': [10, 10, 10, 10, 10, 10, 16, 10, 10, 10, 10, 10, 16, 10, 10, 10, 10,\n",
            "            10, 0, 10, 10, 10, 10, 10],\n",
            " 'sentence': ['Thousands', 'of', 'demonstrators', 'have', 'marched', 'through',\n",
            "              'London', 'to', 'protest', 'the', 'war', 'in', 'Iraq', 'and',\n",
            "              'demand', 'the', 'withdrawal', 'of', 'British', 'troops', 'from',\n",
            "              'that', 'country', '.']}\n"
          ]
        }
      ],
      "source": [
        "example = dataset['train'][0]\n",
        "pprint(example, compact=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1gUQv5pI0dLI"
      },
      "outputs": [],
      "source": [
        "model_name = \"dslim/distilbert-NER\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PeG3ksZD0dLJ",
        "outputId": "f22b9c48-877f-49dd-9252-32b5499b03f6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'input_ids': [101, 26159, 1104, 8568, 4487, 5067, 1138, 9639, 1194, 1498, 1106, 5641, 1103, 1594, 1107, 5008, 1105, 4555, 1103, 10602, 1104, 1418, 2830, 1121, 1115, 1583, 119, 102], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "inputs = tokenizer(example['sentence'], is_split_into_words=True)\n",
        "inputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IdZkqGoX0dLJ",
        "outputId": "f4fd40c0-4fd6-415c-c3ad-b644c5982230"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'[CLS] Thousands of demonstrators have marched through London to protest the war in Iraq and demand the withdrawal of British troops from that country. [SEP]'"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tokenizer.decode(inputs['input_ids'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NowYs8S80dLK"
      },
      "outputs": [],
      "source": [
        "def tokenize_and_align_labels(examples):\n",
        "    tokenized_inputs = tokenizer(examples[\"sentence\"], is_split_into_words=True)\n",
        "\n",
        "    labels = []\n",
        "    for i, label in enumerate(examples[f\"labels\"]):\n",
        "        word_ids = tokenized_inputs.word_ids(batch_index=i)  # Map tokens to their respective word.\n",
        "        previous_word_idx = None\n",
        "        label_ids = []\n",
        "        for word_idx in word_ids:  # Set the special tokens to -100.\n",
        "            if word_idx is None:\n",
        "                label_ids.append(-100)\n",
        "            elif word_idx != previous_word_idx:  # Only label the first token of a given word.\n",
        "                label_ids.append(label[word_idx])\n",
        "            else:\n",
        "                label_ids.append(-100)\n",
        "            previous_word_idx = word_idx\n",
        "        labels.append(label_ids)\n",
        "\n",
        "    tokenized_inputs[\"labels\"] = labels\n",
        "    return tokenized_inputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A9kwM7XY0dLK",
        "outputId": "a52a5161-042d-4639-ae5c-50a22b9f0091",
        "colab": {
          "referenced_widgets": [
            "fec920ad54bc4ccaa44b0dd0b8637f59",
            "ac840a96dac34dcc94dd70948c2c1693",
            "6eb12dfa51c7405eab2fd5c214594e97"
          ]
        }
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fec920ad54bc4ccaa44b0dd0b8637f59",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/33570 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ac840a96dac34dcc94dd70948c2c1693",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/7194 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6eb12dfa51c7405eab2fd5c214594e97",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/7194 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['sentence', 'labels', 'input_ids', 'attention_mask'],\n",
              "        num_rows: 33570\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['sentence', 'labels', 'input_ids', 'attention_mask'],\n",
              "        num_rows: 7194\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['sentence', 'labels', 'input_ids', 'attention_mask'],\n",
              "        num_rows: 7194\n",
              "    })\n",
              "})"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tokenized_dataset = dataset.map(tokenize_and_align_labels, batched=True)\n",
        "tokenized_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ydZD5LOE0dLK"
      },
      "outputs": [],
      "source": [
        "seqeval = evaluate.load(\"seqeval\")\n",
        "\n",
        "def compute_metrics(p):\n",
        "    predictions, labels = p\n",
        "    predictions = np.argmax(predictions, axis=2)\n",
        "\n",
        "    true_predictions = [\n",
        "        [unique_labels[p] for (p, l) in zip(prediction, label) if l != -100]\n",
        "        for prediction, label in zip(predictions, labels)\n",
        "    ]\n",
        "    true_labels = [\n",
        "        [unique_labels[l] for (p, l) in zip(prediction, label) if l != -100]\n",
        "        for prediction, label in zip(predictions, labels)\n",
        "    ]\n",
        "\n",
        "    results = seqeval.compute(predictions=true_predictions, references=true_labels)\n",
        "    return {\n",
        "        \"precision\": results[\"overall_precision\"],\n",
        "        \"recall\": results[\"overall_recall\"],\n",
        "        \"f1\": results[\"overall_f1\"],\n",
        "        \"accuracy\": results[\"overall_accuracy\"],\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dwi3cI4x0dLL"
      },
      "outputs": [],
      "source": [
        "data_collator = DataCollatorForTokenClassification(tokenizer=tokenizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VKkceshy0dLL",
        "outputId": "a7516b38-153e-41fc-eae8-d013e50f2292"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of DistilBertForTokenClassification were not initialized from the model checkpoint at dslim/distilbert-NER and are newly initialized because the shapes did not match:\n",
            "- classifier.bias: found shape torch.Size([9]) in the checkpoint and torch.Size([17]) in the model instantiated\n",
            "- classifier.weight: found shape torch.Size([9, 768]) in the checkpoint and torch.Size([17, 768]) in the model instantiated\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "model = AutoModelForTokenClassification.from_pretrained(model_name, num_labels=len(id2label), id2label=id2label, label2id=label2id, ignore_mismatched_sizes=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vJKb9LRp0dLL",
        "outputId": "73675dc4-fed0-49dc-8e9e-c5aea43a1c46"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2625' max='2625' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2625/2625 06:40, Epoch 5/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.174700</td>\n",
              "      <td>0.102826</td>\n",
              "      <td>0.804568</td>\n",
              "      <td>0.818566</td>\n",
              "      <td>0.811507</td>\n",
              "      <td>0.968424</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.096700</td>\n",
              "      <td>0.093920</td>\n",
              "      <td>0.824543</td>\n",
              "      <td>0.827147</td>\n",
              "      <td>0.825843</td>\n",
              "      <td>0.970690</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.081600</td>\n",
              "      <td>0.090497</td>\n",
              "      <td>0.827020</td>\n",
              "      <td>0.831258</td>\n",
              "      <td>0.829133</td>\n",
              "      <td>0.971317</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.072500</td>\n",
              "      <td>0.090941</td>\n",
              "      <td>0.826589</td>\n",
              "      <td>0.836144</td>\n",
              "      <td>0.831339</td>\n",
              "      <td>0.971678</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.067100</td>\n",
              "      <td>0.091911</td>\n",
              "      <td>0.828920</td>\n",
              "      <td>0.837514</td>\n",
              "      <td>0.833195</td>\n",
              "      <td>0.971798</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/saurabh/anaconda3/envs/lighting/lib/python3.8/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "TrainOutput(global_step=2625, training_loss=0.09693791089739118, metrics={'train_runtime': 402.2692, 'train_samples_per_second': 417.258, 'train_steps_per_second': 6.525, 'total_flos': 2307060033162216.0, 'train_loss': 0.09693791089739118, 'epoch': 5.0})"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "training_args = TrainingArguments(\n",
        "    output_dir=\"checkpoints_logs\",\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=64,\n",
        "    per_device_eval_batch_size=32,\n",
        "    num_train_epochs=5,\n",
        "    weight_decay=0.01,\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_dataset[\"train\"],\n",
        "    eval_dataset=tokenized_dataset[\"validation\"],\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=data_collator,\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n",
        "\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ZeLdEz_0dLM"
      },
      "source": [
        "## Test Accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wcaULcUb0dLM",
        "outputId": "bc36a150-56b2-4f78-932a-6449c5b324c1"
      },
      "outputs": [
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "{'test_loss': 0.09210649877786636,\n",
              " 'test_precision': 0.8253578732106339,\n",
              " 'test_recall': 0.8390354003326206,\n",
              " 'test_f1': 0.8321404376896115,\n",
              " 'test_accuracy': 0.9718371161206908,\n",
              " 'test_runtime': 7.75,\n",
              " 'test_samples_per_second': 928.263,\n",
              " 'test_steps_per_second': 29.032}"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "results = trainer.predict(tokenized_dataset['test'])\n",
        "results[2]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mYOnEP1z0dLN"
      },
      "source": [
        "## Inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8yoE6ilx0dLN"
      },
      "outputs": [],
      "source": [
        "from transformers import pipeline\n",
        "classifier = pipeline(\"ner\", model= model , tokenizer = tokenizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q5oH-t310dLN",
        "outputId": "25e0bbc9-9b9d-4078-d31e-25074bc9789f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "True Labels :\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[('since', 'B-tim'),\n",
              " ('May', 'I-tim'),\n",
              " ('Camp', 'B-geo'),\n",
              " ('Pendleton', 'I-geo'),\n",
              " ('California', 'B-geo')]"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "example = dataset['test'][1110]\n",
        "true_labels = [id2label[label] for label in example['labels']]\n",
        "print(\"True Labels :\")\n",
        "[p for p in zip(example['sentence'], true_labels) if p[1]!='O']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dVZH645s0dLN",
        "outputId": "82791269-5360-44d4-c351-78536d092976"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Pred Labels :\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[('since', 'B-tim'),\n",
              " ('May', 'I-tim'),\n",
              " ('Camp', 'B-geo'),\n",
              " ('Pendleton', 'I-geo'),\n",
              " ('California', 'B-geo')]"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "## Predictions\n",
        "print(\"Pred Labels :\")\n",
        "preds = classifier(\" \".join(example['sentence']))\n",
        "[(p['word'], p['entity']) for p in preds]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4C-X5xI40dLO"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "lighting",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.18"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}